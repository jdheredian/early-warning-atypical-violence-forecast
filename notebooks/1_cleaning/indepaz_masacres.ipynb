{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ab980f",
   "metadata": {},
   "source": [
    "<img src=\"https://industrial.uniandes.edu.co/sites/default/files/imagenes/uniandeslogo.png\" alt=\"Universidad de los Andes\" style=\"float: right; width: 300px; height: auto;\">\n",
    "\n",
    "# Cleaning Indepaz Massacres data\n",
    "\n",
    "Autor: Juan Diego Heredia Niño \n",
    "\n",
    "Email: jd.heredian@uniandes.edu.co\n",
    "\n",
    "Date: Nov 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31df49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports the core libraries required for data processing and configuration management\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "import yaml  # To read YAML configuration files\n",
    "from pathlib import Path  # For cross-platform file path handling\n",
    "import yaml  # To read YAML configuration files\n",
    "from pathlib import Path  # For cross-platform file path handling\n",
    "from rapidfuzz import fuzz, process  # Fuzzy string matching algorithms\n",
    "# The rapidfuzz library is used for fuzzy string matching between municipality names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0ba7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The configuration file contains the directory structure used throughout the project\n",
    "# This approach ensures consistent path references across different notebooks and scripts\n",
    "with open('paths.yml', 'r') as file:\n",
    "    paths = yaml.safe_load(file)  # Read and parse YAML file\n",
    "\n",
    "# Path objects are created for each data stage in the pipeline\n",
    "# The raw directory contains original unprocessed data from external sources\n",
    "# The temp directory stores intermediate processing outputs\n",
    "# The processed directory holds final cleaned datasets ready for analysis\n",
    "raw = Path(paths['data']['raw'])  # Directory with raw data\n",
    "temp = Path(paths['data']['temp'])  # Directory with temporary processed data\n",
    "processed = Path(paths['data']['processed'])  # Directory with final processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63eb04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function standardizes column headers from scraped HTML tables\n",
    "# Web-scraped data often has inconsistent header formats that require normalization\n",
    "def fix_headers(df):\n",
    "    # Some tables have numeric column names instead of proper headers\n",
    "    # In such cases, the first row contains the actual column names\n",
    "    if list(df.columns) == list(range(df.shape[1])):\n",
    "        new_cols = df.iloc[0] #['id','Fecha', 'Departamento', 'Municipio', '# de víctimas']\n",
    "        df = df[1:].copy()  # Exclude the header row from data\n",
    "        df.columns = new_cols\n",
    "    # Standardizes the numbering column identifier\n",
    "    elif 'N°' in df.columns:\n",
    "        df.rename(columns={'N°':'#'}, inplace=True)\n",
    "    # Column names are converted to lowercase for consistency\n",
    "    df.columns = [x.lower() for x in df.columns.to_list()]\n",
    "    # Spanish column names are translated to English abbreviations\n",
    "    # This standardization facilitates downstream processing and analysis\n",
    "    df = (\n",
    "        df\n",
    "        .rename(\n",
    "            columns={\n",
    "                '# de víctimas':'qty',  # Number of victims\n",
    "                'fecha':'date',  # Date of the massacre\n",
    "                'departamento':'dep',  # Department (first-level administrative division)\n",
    "                'municipio':'old_mun'  # Municipality (second-level administrative division)\n",
    "            }\n",
    "        )\n",
    "        .drop(columns='#')  # The row number column is not needed for analysis\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea192cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates standardized matching keys for geographic location names\n",
    "# Standardization is necessary because municipality names may have spelling variations\n",
    "def make_key(df):\n",
    "    # The key combines department and municipality names into a single searchable string\n",
    "    # Missing values are replaced with empty strings to avoid concatenation errors\n",
    "    # Punctuation marks are removed as they introduce unnecessary variation\n",
    "    # Text normalization removes accents and special characters through Unicode decomposition\n",
    "    # All text is converted to lowercase to ensure case-insensitive matching\n",
    "    return (\n",
    "        df[['dep', 'mun']]\n",
    "        .fillna('')  # Handle missing values\n",
    "        .replace(r'[.,]', '', regex=True)  # Remove punctuation\n",
    "        .agg(' '.join, axis=1)  # Concatenate department and municipality\n",
    "        .str.lower()  # Convert to lowercase\n",
    "        .str.normalize('NFKD')  # Unicode normalization\n",
    "        .str.encode('ascii', 'ignore')  # Remove accents and special characters\n",
    "        .str.decode('utf-8')  # Decode back to string\n",
    "        .str.strip()  # Remove leading and trailing whitespace\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7112b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell performs the main data extraction and cleaning from the Indepaz website\n",
    "# The Indepaz organization maintains a comprehensive database of massacres in Colombia\n",
    "# Data is scraped from multiple HTML tables on their webpage\n",
    "list_of_dfs = [\n",
    "            fix_headers(df)  # Each table is standardized using the previously defined function\n",
    "            for df in \n",
    "            pd.read_html(\"https://indepaz.org.co/informe-de-masacres-en-colombia-durante-el-2020-2021/comment-page-4/\")\n",
    "        ]\n",
    "\n",
    "# All tables are combined into a single dataset\n",
    "df_massacres = pd.concat(\n",
    "        list_of_dfs\n",
    "        , ignore_index=True\n",
    "        )\n",
    "\n",
    "# Date formats in the source data are inconsistent and require standardization\n",
    "# Some dates use two-digit years that need to be converted to four-digit format\n",
    "dates = df_massacres['date'].astype(str).str.strip()\n",
    "# Two-digit years are assumed to be in the 2000s and are converted accordingly\n",
    "dates.loc[dates.str.match(r'\\d{1,2}/\\d{1,2}/\\d{2}$')] = dates.loc[dates.str.match(r'\\d{1,2}/\\d{1,2}/\\d{2}$')].str.replace(r'(\\d{1,2}/\\d{1,2}/)(\\d{2})$', r'\\g<1>20\\2', regex=True)\n",
    "\n",
    "# Dates are parsed with day-first format, which is standard in Colombian data\n",
    "# Invalid dates are coerced to NaT (Not a Time) to prevent parsing errors\n",
    "df_massacres['date'] = pd.to_datetime(dates, dayfirst=True, errors='coerce')\n",
    "# Dates are aggregated to monthly frequency for temporal analysis\n",
    "# This aggregation reduces noise while preserving important temporal patterns\n",
    "df_massacres['date'] = df_massacres['date'].dt.to_period('M').dt.to_timestamp().dt.date\n",
    "\n",
    "# Only records with valid numeric victim counts are retained\n",
    "# Non-numeric entries likely represent data quality issues or missing information\n",
    "mask = pd.to_numeric(df_massacres['qty'], errors='coerce').notna()\n",
    "df_massacres = df_massacres[mask].copy()\n",
    "df_massacres['qty'] = df_massacres['qty'].astype(int)\n",
    "\n",
    "# Geographic names are standardized to title case for consistency\n",
    "# Accents and special characters are removed to facilitate matching with official codes\n",
    "df_massacres[['dep', 'old_mun']] = (\n",
    "        df_massacres[['dep', 'old_mun']]\n",
    "        .apply(\n",
    "                lambda x: \n",
    "                    x\n",
    "                    .str.title()  # Convert to title case\n",
    "                    .str.normalize('NFKD')  # Unicode normalization\n",
    "                    .str.encode('ascii', errors='ignore')  # Remove accents\n",
    "                    .str.decode('utf-8')  # Decode back to string\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f810fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell performs geographic entity resolution by matching municipality names to official codes\n",
    "# Some entries list multiple municipalities, which are split into separate records\n",
    "df_massacres_mun = (\n",
    "    df_massacres[['dep','old_mun']]\n",
    "    .assign(\n",
    "        # Multiple municipalities in a single entry are separated by commas or the conjunction \"Y\"\n",
    "        mun=df_massacres['old_mun']\n",
    "        .str.replace(r'\\s+Y\\s+', ',', regex=True)  # Replace 'Y' (and) with comma separator\n",
    "        .str.split(r'\\s*,\\s*')  # Split on commas to create lists of municipalities\n",
    "    )\n",
    "    .explode('mun')  # Create separate rows for each municipality\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# The DIVIPOLA dataset contains official municipality codes from Colombia's national statistics agency\n",
    "# These codes are necessary for linking with other official datasets\n",
    "df_divipola = pd.read_parquet(temp / 'dane'/ 'divipola' / 'divipola.parquet') \n",
    "\n",
    "# Standardized keys are created for both datasets to enable fuzzy matching\n",
    "df_massacres_mun['match_key'] = make_key(df_massacres_mun)\n",
    "df_divipola['match_key'] = make_key(df_divipola)\n",
    "\n",
    "# The list of official municipality keys serves as the reference for matching\n",
    "choices = df_divipola['match_key'].tolist()\n",
    "\n",
    "# Fuzzy string matching is used because exact matching would miss valid entries due to spelling variations\n",
    "# The token sort ratio algorithm accounts for word order differences and partial matches\n",
    "matches = []\n",
    "for idx, key in df_massacres_mun['match_key'].items():\n",
    "    # Each massacre municipality is matched to the most similar DIVIPOLA entry\n",
    "    match, score, pos = process.extractOne(key, choices, scorer=fuzz.token_sort_ratio)\n",
    "    # A threshold of 85 percent similarity balances precision and recall\n",
    "    # Lower thresholds would increase false matches, while higher thresholds would miss valid matches\n",
    "    if score >= 85:  # ajusta el umbral\n",
    "        matches.append({\n",
    "            'mass_idx': idx,\n",
    "            'divi_idx': df_divipola.index[pos],\n",
    "            'score': score\n",
    "        })\n",
    "\n",
    "# The matches are converted to a dataframe for merging\n",
    "matches = pd.DataFrame(matches)\n",
    "\n",
    "# Both datasets are merged based on the fuzzy matching results\n",
    "result = (\n",
    "    df_massacres_mun\n",
    "    .merge(matches, left_index=True, right_on='mass_idx', how='left')\n",
    "    .merge(df_divipola, left_on='divi_idx', right_index=True, suffixes=('_mass', '_divi'))\n",
    ")\n",
    "\n",
    "# Manual corrections are applied for cases where fuzzy matching produces incorrect results\n",
    "# Cali is the capital of Valle del Cauca and was incorrectly matched to Calima\n",
    "result['cod_mun'] = np.where(\n",
    "    result['dep_mass'].isin(['Valle Del Cauca']) &\n",
    "    result['dep_divi'].isin(['Valle Del Cauca']) &\n",
    "    result['mun_mass'].isin(['Cali']) &\n",
    "    result['mun_divi'].isin(['Calima']) &\n",
    "    (result['score'] < 100), '76001', result['cod_mun']  # Official code for Cali\n",
    ")\n",
    "\n",
    "# Cucuta is the capital of Norte de Santander and was incorrectly matched to Cucutilla\n",
    "result['cod_mun'] = np.where(\n",
    "    result['dep_mass'].isin(['Norte De Santander']) &\n",
    "    result['dep_divi'].isin(['Norte De Santander']) &\n",
    "    result['mun_mass'].isin(['Cucuta']) &\n",
    "    result['mun_divi'].isin(['Cucutilla']) &\n",
    "    (result['score'] < 100), '54001', result['cod_mun']  # Official code for Cucuta\n",
    ")\n",
    "\n",
    "# The final municipality mapping is extracted for merging back to the main dataset\n",
    "df_mun = (\n",
    "        result\n",
    "        [['dep_mass', 'old_mun','cod_mun']]\n",
    "        .drop_duplicates()  # Each unique municipality appears only once\n",
    "        .rename(columns={'dep_mass':'dep'})\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e048b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros actualizados:\n",
      "                 dep           old_mun cod_mun\n",
      "5    Valle Del Cauca              Buga   76111\n",
      "12       Bogota D.C.       Bogota D.C.   11001\n",
      "28            Narino       Magui Payan   52427\n",
      "46      Cundinamarca        El Colegio   25245\n",
      "167           Bogota            Bogota   11001\n",
      "195            Cauca          Piendamo   19548\n",
      "211       Bogota D.C        Bogota D.C   11001\n",
      "212           Narino            Tumaco   52835\n",
      "250           Narino      Colon Genova   52203\n",
      "260         Putumayo  Puerto Leguizamo   86573\n",
      "274          Bolivar         Cartagena   13001\n",
      "354           Bogota   Bogota  Sumapaz   11001\n",
      "357           Narino   Andes-Sotomayor   52418\n",
      "402           Tolima        Rio Blanco   73616\n",
      "434         Putumayo         Leguizamo   86573\n"
     ]
    }
   ],
   "source": [
    "# The municipality codes are merged back into the main massacre dataset\n",
    "df_massacres = df_massacres.merge(\n",
    "    df_mun,\n",
    "    on=['dep', 'old_mun'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Some municipalities require manual coding due to name ambiguities or variations\n",
    "# These cases were identified during data validation and represent edge cases\n",
    "# The dictionary maps department-municipality pairs to their official DIVIPOLA codes\n",
    "codigos_divipola = {\n",
    "    ('Valle Del Cauca', 'Buga'): '76111',  # Guadalajara de Buga\n",
    "    ('Narino', 'Magui Payan'): '52427',  # Alternative spelling of Magüí Payán\n",
    "    ('Cundinamarca', 'Mesitas Del Colegio'): '25245',  # El Colegio\n",
    "    ('Bogota', 'Bogota'): '11001',  # Capital district\n",
    "    ('Cauca', 'Piendamo'): '19548',  # Alternative spelling of Piendamó\n",
    "    ('Narino', 'Tumaco'): '52835',  # San Andrés de Tumaco\n",
    "    ('Narino', 'Colon Genova'): '52203',  # Colón\n",
    "    ('Bolivar', 'Cartagena'): '13001',  # Cartagena de Indias\n",
    "    ('Bogota', 'Bogota  Sumapaz'): '11001',  # Sumapaz is a rural locality within Bogotá\n",
    "    ('Narino', 'Andes-Sotomayor'): '52418',  # Los Andes-Sotomayor\n",
    "    ('Tolima', 'Rio Blanco'): '73616',  # Ríoblanco\n",
    "    ('Putumayo', 'Leguizamo'): '86573'  # Puerto Leguízamo\n",
    "}\n",
    "\n",
    "# The codes are applied to the corresponding records in the dataset\n",
    "for (dep, mun), codigo in codigos_divipola.items():\n",
    "    mask = (df_massacres['dep'] == dep) & (df_massacres['old_mun'] == mun)\n",
    "    df_massacres.loc[mask, 'cod_mun'] = codigo\n",
    "\n",
    "# The updates are verified to ensure they were applied correctly\n",
    "print(\"Registros actualizados:\")\n",
    "print(df_massacres[df_massacres['cod_mun'].isin(codigos_divipola.values())][['dep', 'old_mun', 'cod_mun']].drop_duplicates())\n",
    "\n",
    "# The final dataset is aggregated by month and municipality\n",
    "# Multiple massacres in the same municipality-month are summed to get total victims\n",
    "df_massacres = df_massacres.groupby(['date','cod_mun'])['qty'].sum().reset_index()\n",
    "\n",
    "# The cleaned data is saved in parquet format for efficient storage and retrieval\n",
    "# Parquet preserves data types and provides compression, making it ideal for analytical workflows\n",
    "df_massacres.to_parquet(\n",
    "        temp / 'indepaz' / 'masacres' / 'massacres.parquet',\n",
    "        index=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
